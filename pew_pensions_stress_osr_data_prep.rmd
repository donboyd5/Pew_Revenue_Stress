---
title: "Own-source revenue for pension stress tests -- data preparation"
author: "Don Boyd"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook:
    df_print: paged
    fig_height: 6
    fig_width: 8
    toc: yes
editor_options:
  chunk_output_type: console
---


```{r setup, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include=FALSE)
options(width = 150)
```


```{r globals}

```


```{r libraries, include=FALSE}
source(here::here("include", "libraries.r"))
devtools::session_info()
```

<!--
Note:
- save all dollar amounts in ONETIME sections as nominal, Millions, state fiscal year basis
unless otherwise specified

-->


# Data preparation overview

Get individual data files, and with certain exceptions: 
- put on state fiscal year basis (except capital gains)
- in common format with columns:
  year, name, value, stabbr, src, fullname
and then combine, putting in nominal $ millions
  (include real versions of some variables; and have gdp price index)
  
*   GDP:
  +   Get Moody's GDP data
  +   Get US gdp history
  +   Get US gdp forecasts
  +   Splice US gdp history and forecasts
  +   Get state gdp history
  +   Use Moody's national-state differences to create a state gdp forecast for each US gdp forecast

*   State tax history
  +   Get osr history
  +   Update to 2020 using qtax and state gdp forecast for 2020

*   Other data
  +   US capital gains
  +   State capital gains
  

# National and state GDP history from BEA

```{r ONETIME_usgdp_history, eval=FALSE}
comment(nipa) # NIPA data all tables, Annual, quarterly, and monthly, latest item released: 2020-12-22
getNIPATable("1.1.5") # nominal gdp
# A191RC nominal gdp, Gross domestic product, Current Dollars, Level 
# A191RX real gdp, Gross domestic product, Chained Dollars, Level

nipa %>%
  filter(str_detect(vdesc, "Gross domestic product"), freq=="Q") %>%
  select(vname, vdesc) %>%
  distinct()

# create fiscal year real and nominal gdp
gdpdata <- nipa %>%
  filter(vname %in% c("A191RC", "A191RX"), freq=="Q") 
summary(gdpdata) # 2020q3 is latest; amounts already are in millions

gdphist <- gdpdata %>%
  filter(date < "2020-07-01") %>%
  mutate(year=ifelse(month(date) > 6, year(date) + 1, year(date))) %>%
  group_by(year, vname) %>%
  summarise(n=n(), value=mean(value), .groups="drop") %>%
  filter(n == 4) %>%
  mutate(name=case_when(vname=="A191RC" ~ "gdp",
                        vname=="A191RX" ~ "rgdp",
                        TRUE ~ "ERROR")) %>%
  select(year, name, value) %>%
  pivot_wider() %>%
  mutate(pgdp=gdp / rgdp) %>%
  pivot_longer(cols=-c(year)) %>%
  mutate(stabbr="US",
         src="nipa")
summary(gdphist)
           
saveRDS(gdphist, here::here("data", "usgdp_history.rds"))
# tmp <- readRDS(here::here("data", "usgdp_history.rds"))
# summary(tmp)  # 1947-2020
# rm(tmp)
rm(gdpdata, gdphist)

```


```{r ONETIME_stgdp_history, eval=FALSE}
# year, name, value, stabbr, src, fullname

# bea history from quarterly back to 2006, convert to sfy
dfq <- sgdp.q %>%
  mutate(year = ifelse(month(date) <= 6, year(date), year(date) + 1)) %>%
  select(-date) %>%
  pivot_longer(cols = c(gdp, rgdp)) %>%
  group_by(stabbr, year, name) %>%
  summarise(n=n(),
            value=mean(value), .groups="drop") %>%
  filter(n==4) %>%
  mutate(src="bea.q")
dfq

# bea history from annual 1964-2019, calendar year (we want sfy)
# convert to July 1 sfy basis
dfa <- sgdp_spliced.a %>%
  arrange(year, name) %>%
  group_by(stabbr, name) %>%
  # average gdp over 2 years
  mutate(lgdp=value[match(year -1, year)],
         value=(value + lgdp) / 2,
         src="bea.a") %>%
  ungroup() %>%
  filter(!is.na(value)) %>%
  select(year, stabbr, value, name, src)

bind_rows(dfq, dfa) %>%
  # filter(name=="gdp", year >=2000) %>%
  filter(name=="gdp", stabbr=="MA") %>%
  ggplot(aes(year, value, colour=src)) +
  geom_line() +
  geom_point()

# splice dfq and dfa
dfa2 <- dfa %>%
  group_by(stabbr, src, name) %>%
  mutate(r2006=value / value[year==2006]) %>%  # ratio vs 2006
  ungroup

dfall <- dfq %>%
  select(year, stabbr, name, val.q=value) %>%
  right_join(dfa2 %>% select(year, stabbr, name, r2006, val.a=value),
            by=c("year", "stabbr", "name")) %>%
  arrange(name, year) %>%
  group_by(stabbr, name) %>%
  mutate(value=ifelse(year >= 2006, val.q, val.q[year==2006]*r2006)) %>%
  ungroup %>%
  filter(!is.na(value))
  
dfall  

dfall %>%
  filter(name=="gdp", year>=0, stabbr=="NJ") %>%
  select(year, val.q, val.a, value) %>%
  pivot_longer(-year) %>%
  ggplot(aes(year, value, colour=name)) +
  geom_line() +
  geom_point() 

# looks good, save
dfsave <- dfall %>%
  filter(stabbr != "US") %>%
  select(year, name, value, stabbr)
saveRDS(dfsave, here::here("data", "stgdp_history.rds"))
summary(dfsave)
count(dfsave, stabbr) # DC and 50 states

# rm(dfq, dfa, dfa2, dfall, dfsave)
#  %>%  mutate(value=value / 1000)  # convert from thousands to millions

```


# National gdp forecasts

Create data frames that have year, <name> where year is a fiscal year and <name> has nominal gdp in $ millions.


```{r file_notes}
# files received from Kimberly Burnham Jan 6 and 7 2020

# Baseline and Downside Scenario 12_21_20.xlsx
#   CBO and fed alt severe growth rates
#   y0-y10 each; y11-20 avg
#   prob calendar year
#   prob massaged by Pew
#   need to find out what they are

# Moody State Population December 2020.xlsx
#   50-state pop
#   1900Q2 to 2050q4
#   thousands
#   Dec 2020 baseline

# Moody's GSP December 2020.xlsx
#  50-state GDP
#  quarterly
#  1977Q1 to 2050q4
#  $ billions SAAR
#  Dec 2020 baseline

# Moody's State Employment December 2020.xlsx
#  50-state eea
#  quarterly
#  1977Q1 to 2050q4
#  thousands
#  Dec 2020 baseline

# Moodys State Household Income December 2020.xlsx
#  50-state median HHI
#  quarterly
#  1977Q1 to 2050q4
#  dollars
#  Dec 2020 baseline

# Moodys State Pop Age December 2020.xlsx
#  50-state population by 5-year age groups
#  thousands
#  1970Q2 to 2050q4
#  dollars
#  Dec 2020 baseline

# Moodys GSP July 2020.xlsx
#  50-state GDP
#  quarterly
#  1977Q1 to 2050q4
#  $ billions SAAR
#  July 2020 baseline

# mutate(year=str_sub(yq, 1, 4) %>% as.numeric,
#        q=str_sub(yq, -1, -1) %>% as.numeric,
#        year=ifelse(q >= 3, year + 1, year))


```


```{r}

# pewfiles <- c("Baseline and Downside Scenario 12_21_20.xlsx",
#              "Moody State Population December 2020.xlsx",
#              "Moody's GSP December 2020.xlsx",
#              "Moodys State Household Income December 2020.xlsx",
#              "Moodys State Pop Age December 2020.xlsx",
#              "Moodys GSP July 2020.xlsx")

```


## National gdp forecast from CBO Feb 2021
```{r}
# year, cbo_feb2021
fn <- "51135-2021-02-economicprojections.xlsx"
(yqvec <- paste0(2017:2031, "Q"))
(cnames <- paste0(rep(yqvec, each=4), 1:4))
dfq <- read_excel(here::here("ignore", "CBO", "Feb2021", fn), 
           sheet="1. Quarterly",
           range="E9:BL9",
           col_names=cnames) %>%
  pivot_longer(-0) %>%
  mutate(date=qy(str_sub(name, -1) %>%
                   as.numeric,
                 str_sub(name, 1, 4) %>% as.numeric))
dfq

gdp_cbo_feb2021 <- dfq %>%
  mutate(year=ifelse(month(date) <= 6,
                     year(date),
                     year(date) + 1)) %>%
  filter(year %in% 2018:2031) %>%
  group_by(year) %>%
  summarise(cbo_feb2021=mean(value) * 1000)


```



## National gdp forecasts from Pew "GDP MASTER FILE_20201021.xlsx"

*   CBO pre-COVID
*   CBO July
*   Moody's 50th July
*   Fed Alt Severe

```{r}
# CBO pre-COVID	CBO July	Moody's 50th July	Lena Fed W	Fed Alt Severe
gdpfn <- "GDP MASTER FILE_20201021.xlsx"
vnames <- c("cbo_precovid", "cbo_jul2020", "moodys_jul2020p50", "lena_fed", "fedalt")

sfy <- read_excel(here::here("ignore", "pew", gdpfn), 
                  sheet="GDP", range="A3:A14", col_names = "year")
# CBO pre-COVID	CBO July	Moody's 50th July	Lena Fed W	Fed Alt Severe
# moodys_jul2020
gdp <- read_excel(here::here("ignore", "pew", gdpfn), 
                  sheet="GDP", 
                   range="G3:K14", col_names=vnames)
# keep only the FY values, not the Q2 values

gdp_master <- tibble(sfy, gdp) %>%
  select(-lena_fed) %>%
  mutate(across(.cols=-year, ~ . * 1000))
gdp_master  # good, no missing values

```


## National GDP forecasts from Moody's July 2020 (p50 and p90) 

*   "Moody's 50 and 90 July.xlsx", sheet: "GDP"
*   quarterly, convert to state fiscal year

```{r}
# this first file has history AND forecasts of nominal GDP, quarterly
# July 2020 baseline and S3 (severe stress scenario), US, 1947q1, 2050q4
# the baseline is the same as what is in the second file

# Moody's 50 and 90 July.xlsx
# get Moody's nominal gdp baseline and S3, July
mfn <- "Moody's 50 and 90 July.xlsx"
moodys <- read_excel(here::here("ignore", "pew", mfn), 
                    sheet="GDP", range="A6:C421", col_names = c("yq", "moodys50", "moodys90"))
gdp_moodys_jul2020 <- moodys %>%
  mutate(year=str_sub(yq, 1, 4) %>% as.numeric,
         q=str_sub(yq, -1, -1) %>% as.numeric,
         year=ifelse(q >= 3, year + 1, year)) %>%
  group_by(year) %>%
  summarise(n=n(),
            moodys_jul2020p50=mean(moodys50),
            moodys_jul2020p90=mean(moodys90),
            .groups="drop") %>%
  filter(n == 4) %>%
  select(-n) %>%
  mutate(across(.cols=-year, ~ . * 1000))  # put in $ millions
summary(gdp_moodys_jul2020)

```


## Moody's national GDP forecasts Dec 2019 and Dec 2020
```{r ONETIME_get_moodysdec20192020_US, eval=FALSE}
dyq <- function(yqdate){
  year <- str_sub(yqdate, 1, 4)
  qtr <- str_sub(yqdate, 6)
  month <- (as.integer(qtr) - 1) * 3 + 1  # first month of quarter
  as.Date(paste(year, month, 1, sep="-"))
  # dyq("2020q3")
}

get_moodys <- function(fname, vname){
  df <- read_excel(here::here("ignore", "pew", fname))

  df2 <- df %>%
    setNames(c("date", "value")) %>%
    filter(row_number() >= 5) %>%
    mutate(date=dyq(date),
           value=as.numeric(value),
           year=ifelse(month(date) >= 7, 
                       year(date) + 1,
                       year(date))) %>%
    group_by(year) %>%
    summarise(n=n(), value=mean(value)) %>%
    filter(n==4) %>%
    mutate(value=value * 1000) %>%
    select(year, !!vname:=value)
  
  df2
}


mdec2019 <- "Moody's GDP December 2019.xlsx"
mdec2020 <- "Moody's GDP December 2020.xlsx"

gdp_moodys_dec2019 <- get_moodys(mdec2019, "moodys_dec2019")
summary(gdp_moodys_dec2019)

gdp_moodys_dec2020 <- get_moodys(mdec2020, "moodys_dec2020")
summary(gdp_moodys_dec2020)

# compare the Moody's forecasts from Dec 2020 from state sums and from US
tmp <- readRDS(here::here("data", "usgdp_2021-01-21.rds"))

df <- tmp %>%
  select(year, moodys_dec2020) %>%
  mutate(type="statesum") %>%
  bind_rows(gdp_moodys_dec2020 %>% mutate(type="US"))

df %>%
  filter(year %in% 2015:2030) %>%
  ggplot(aes(year, moodys_dec2020, colour=type)) +
  geom_line() +
  geom_point()

df %>%
  group_by(type) %>%
  mutate(pch=moodys_dec2020 / moodys_dec2020[match(year - 1, year)] * 100 - 100) %>%
  filter(year %in% 2015:2030) %>%
  ggplot(aes(year, pch, colour=type)) +
  geom_line(size=1) +
  geom_point() +
  scale_x_continuous(breaks=seq(2010, 2040, 2)) +
  scale_y_continuous(breaks=seq(0, 10, 0.5)) +
  ggtitle("Moody's December 2020 forecasts: National and sum of states (including DC, PR, GU, VI") +
  theme_bw()
# state sum is about 0.25% faster growth for two years, then ~0.2% faster or a little less

```


```{r}
gdp_master %>%
  select(-moodys_jul2020p50) %>%
  left_join(gdp_moodys_jul2020, by="year") %>%
  left_join(gdp_moodys_dec2019, by="year") %>%
  left_join(gdp_moodys_dec2020, by="year") %>%
  left_join(gdp_cbo_feb2021, by="year")

# only minimal differences from history in 2019, but substantial differences in 2020

```


## Create combined US gdp file using BEA history where not provided
```{r}
gdphist <- readRDS(here::here("data", "usgdp_history.rds"))
summary(gdphist)

usgdp1 <- gdphist %>%
  filter(name=="gdp") %>%
  select(year, gdphist=value) %>%
  full_join(gdp_master %>% select(-moodys_jul2020p50), by="year") %>%
  full_join(gdp_moodys_jul2020, by="year") %>%
  full_join(gdp_moodys_dec2019, by="year") %>%
  full_join(gdp_moodys_dec2020, by="year") %>%
  full_join(gdp_cbo_feb2021, by="year")
summary(usgdp1)
# gdp_moody_dec2019
# gdp_moody_dec2020

usgdp1 %>% filter(year %in% 2010:2025)

usgdp1 %>% filter(year %in% 2010:2025) %>%
  mutate(ratio=moodys_dec2020 / gdphist * 10000)

# replace
usgdp <- usgdp1 %>%
  mutate(across(.cols=-c(year, gdphist), ~ ifelse(is.na(.), gdphist, .))) %>%
  filter(year <= 2030)
summary(usgdp) # good, the only NAs are gdphist, which is because it does not have forecasts

usgdp %>%
  select(-gdphist) %>%
  filter(year >= 2015) %>%
  pivot_longer(-year) %>%
  ggplot(aes(year, value, colour=name)) +
  geom_line() +
  geom_point() 

saveRDS(usgdp, here::here("data", "usgdp.rds"))

```



# State gdp forecasts

## State GDP forecasts from Moody's December 2020 "Moody's GSP December 2020.xlsx"

*  "Moody's GSP December 2020.xlsx"


```{r ONETIME_get_moodysdec2020_states_from_Kimberly, eval=FALSE}
# get the quarterly file for the states
# create state fiscal year data, and national fiscal year data

#.. get 50 states gdp ----
fn <- "Moody's GSP December 2020.xlsx"
df <- read_excel(here::here("ignore", "pew", fn))
stnames <- as_tibble(df[4, -1] %>% t, 
                     rownames="abbr",
                     .name_repair = "minimal") %>%
  rename(stname=2)

df2 <- df %>%
  rename(date=1) %>%
  filter(row_number() > 4) %>%
  mutate(date=paste0(str_sub(date, 1, 4), "-", as.numeric(str_sub(date, -1)) * 3 - 2, "-01"),
         date=as.Date(date)) %>%
  pivot_longer(-date, names_to = "abbr") %>%
  mutate(value=as.numeric(value)) %>%
  left_join(stnames, by="abbr") %>%
  mutate(stabbr=str_sub(abbr, -2, -1))
df2
count(df2, stabbr, stname) # 54: 50 states, DC, GU, PR, VI
summary(df2)
  
#.. create fiscal year file for states ---
# CAUTION: July 1 fiscal year for all states
df3 <- df2 %>%
  select(stabbr, stname, date, value) %>%
  mutate(year=year(date),
         year=ifelse(month(date) >= 7, year + 1, year)) %>%
  group_by(stabbr, year) %>%
  summarise(n=n(), value=mean(value) * 1000, .groups = "drop") %>% # put in $ millions
  filter(n==4, !is.na(value))  %>% # the NAs are GU and VI for early years -- drop them
  select(-n)
summary(df3)
count(df3, year)
df3 %>% filter(is.na(value))
saveRDS(df3, here::here("data", "stgdp_moodys_dec2020.rds"))

# .. get US totals DO NOT EXCLUDE GU, PR, VI ----
# ustot <- df3 %>%
#   # filter(!stabbr %in% c("GU", "PR", "VI")) %>%
#   group_by(year) %>%
#   summarise(value=sum(value), n=n())
# summary(ustot)
# 
# gdp_moody_dec2020 <- ustot %>%
#   select(year, moodys_dec2020=value)


```


## Get differences in % change Moody's US vs states
```{r}
usgdp <- readRDS(here::here("data", "usgdp.rds"))
mstgdp <- readRDS(here::here("data", "stgdp_moodys_dec2020.rds"))
stgdphist <- readRDS(here::here("data", "stgdp_history.rds"))

count(mstgdp, stabbr)

pchdiff <- mstgdp  %>% 
  filter(year <= 2030) %>%
  left_join(usgdp %>% select(year, us=moodys_dec2020), by = "year") %>%
  group_by(stabbr) %>%
  mutate(pch=value / value[match(year - 1, year)] * 100 - 100,
         pchus=us / us[match(year - 1, year)] * 100 - 100,
         pdelta=pch - pchus)
pchdiff

# pchdiff %>% filter(stabbr=="NJ")


```


## Apply these % differences to get state gdp forecast for each national forecast (back to 1977)


Use BEA history
And inferred values for 2020 and later


```{r}

uslong <- usgdp %>%
  pivot_longer(cols=-year, names_to = "src") %>%
  group_by(src) %>%
  mutate(pchus=value / value[match(year - 1, year)] * 100 - 100) %>%
  select(year, src, pchus)

stpch <- uslong %>%
  filter(src != "gdphist") %>%
  inner_join(pchdiff %>% 
               filter(!stabbr %in% c("GU", "PR", "VI"),
                      year >= 2019) %>%  # first year with pch
               select(stabbr, year, pdelta),
             by="year") %>%
  arrange(stabbr, src, year) %>%
  group_by(stabbr, src) %>%
  mutate(pch=pchus + pdelta,
         ratio=ifelse(year==2019, 1, 1 + pch / 100),
         ratio2019=cumprod(ratio)) %>%
  ungroup
stpch

count(stpch, src)
stpch %>% filter(stabbr=="NJ", year %in% 2017:2021) %>% arrange(src, year)


# apply the ratios to BEA history
count(stgdphist, name)
df <- stgdphist %>%
  filter(name=="gdp") %>%
  select(year, stabbr, gdphist=value) %>%
  full_join(stpch %>%
              select(year, stabbr, src, ratio2019) %>%
              pivot_wider(names_from=src,
                          values_from=ratio2019),
            by = c("year", "stabbr"))

stgdp <- df %>%
  group_by(stabbr) %>%
  mutate(across(-c(year, gdphist),
                ~ ifelse(year < 2019, gdphist, . * gdphist[year==2019]))) %>%
  ungroup

saveRDS(stgdp, here::here("data", "stgdp.rds"))

```


# Own-source revenue

## OSR history and updating to 2020

```{r ONETIME_censusOSR, eval=FALSE}
# all states
tmp <- count(slgfin, aggvar)

vars <- c("osr", "tottax", "gst", "iit", "cit")
osr <- slgfin %>%
  filter(level==2, aggvar %in% vars) %>%
  select(stabbr, year, aggvar, value) %>%
  mutate(value=value / 1000) %>% # put in $ millions
  pivot_wider(names_from = aggvar) %>%
  mutate(nontax=osr - tottax,
         othertax=tottax - naz(iit) - naz(gst) - naz(cit)) %>%
  arrange(year)
ht(osr)
summary(osr)

osr_long <- osr %>%
  pivot_longer(cols=-c(year, stabbr))

saveRDS(osr_long, here::here("data", "osr_census.rds"))
rm(tmp, vars, osr, osr_long)

```


```{r ONETIME_census_statefin}
# use these data whereever possible

cdir <- "D:/Data/CensusFinanceData/GOVSTIMESERIES.GS00SG01_2021-02-10T134139/"
cfn <- "GOVSTIMESERIES.GS00SG01_data_with_overlays_2021-02-10T134136.csv"

df <- read_csv(paste0(cdir, cfn))
glimpse(df)
count(df, NAME) # 50 states plus bad rec
count(df, YEAR) # 2012-2019
count(df, AGG_DESC, AGG_DESC_LABEL)

df2 <- df %>%
  filter(row_number() > 1,
         AGG_DESC %in% c("SF0003", "SF0004", "SF0005", "SF0006", "SF0009", "SF0010", "SF0013", "SF0014")) %>%
  mutate(name=fct_recode(AGG_DESC,
                         genrev = "SF0003",
                         igr = "SF0004",
                         tottax = "SF0005",
                         gst = "SF0006",
                         iit = "SF0009",
                         cit = "SF0010",
                         charges = "SF0013",
                         misc = "SF0014"),
         stabbr = state.abb[match(NAME, state.name)],
         year=as.integer(YEAR),
         value=as.numeric(AMOUNT)) %>%
  select(stabbr, year, name, value) %>%
  pivot_wider() %>%
  replace(is.na(.), 0) %>%
  mutate(othertax = tottax - iit - gst - cit,
         nontax = charges + misc,
         nontax2 = genrev - igr - tottax,
         osr = tottax + nontax)
  
# naz(iit) + naz(gst) + naz(cit) + naz(othertax)
df2

df3 <- df2 %>%
  select(stabbr, year, cit, gst, iit, nontax, osr, othertax, tottax) %>%
  pivot_longer(-c(stabbr, year)) %>%
  mutate(value=value / 1e3)

saveRDS(df3, here::here("data", "osr_census_recent.rds"))

# osr_long %>% filter(year==2012, stabbr=="AL") %>% mutate(value=value * 1000)
# df2 %>% filter(year==2012, stabbr=="AL")
# + 4949273 - 4902593 
# 
# df3 <- osr_long %>%
#   filter(name=="nontax") %>%
#   mutate(nontax_djb=value * 1000,
#          type="boyd") %>%
#   select(-c(name, value)) %>%
#   inner_join(df2 %>% select(stabbr, year, nontax, nontax2))
# 
# ht(df3)

# stabbr  year name       value

# 1 cit       3172
# 2 gst       3172
# 3 iit       3172
# 4 nontax    3172
# 5 osr       3172
# 6 othertax  3172
# 7 tottax    3172

         # MSR_RESULT_ID = fct_collapse(MMM_MBR_CND_STATUS_CD,
         #                          calc_crg_1 = as.character(1:2),
         #                          calc_crg_2 = as.character(3:4),
         #                          calc_crg_3 = as.character(5:9))) 

```


```{r ONETIME_osrcensus_to2019}
df1 <- readRDS(here::here("data", "osr_census.rds"))
df2 <- readRDS(here::here("data", "osr_census_recent.rds"))
summary(df1)  # 1902-2018
summary(df2)  # 2012 - 2019
count(df1, stabbr)  # includes DC, US
count(df2, stabbr)  # 50 states

df3 <- bind_rows(df1 %>% filter(stabbr %in% state.abb, year < 2012), df2)
summary(df3)
count(df3, stabbr)
count(df3, year)
count(df3, name)
saveRDS(df3, here::here("data", "osr_census_history.rds"))


```




```{r ONETIME_qtax_taxgrowth_for20192020}
# use qtax growth rates to help update osr
# get ratio to 2018 for 2019 and 2020

df <- qtax %>%
  filter(vname %in% c("gst", "iit", "cit", "tottax")) %>%
  select(date, stabbr, name=vname, value) %>%
  mutate(year=ifelse(month(date) > 6,
                     year(date) + 1,
                     year(date))) %>%
  group_by(year, stabbr, name) %>%
  summarise(value=mean(value, na.rm=TRUE),
            .groups="drop") %>%
  pivot_wider() %>%
  mutate(othertax=tottax - naz(cit) - naz(iit) - naz(gst)) %>%
  pivot_longer(-c(year, stabbr))
count(df, name)
ht(df)

taxgrowth <- df %>%
  filter(year >= 2019,
         stabbr %in% state.abb) %>%
  group_by(stabbr, name) %>%
  mutate(ratio=value / value[year==2019]) %>%
  ungroup %>%
  select(year, stabbr, name, ratio)
summary(taxgrowth)

```


```{r ONETIME_nontaxgrowth_for2020}
# for nontax, use 2019 and 2020 gdp growth unless we get other data
stgdp <- readRDS(here::here("data", "stgdp.rds"))

nontaxgrowth <- stgdp %>%
  select(year, stabbr, gdp=cbo_feb2021) %>%
  filter(year %in% 2019:2020) %>%
  mutate(ratio=gdp / gdp[year==2019],
         name="nontax") %>%
  select(year, stabbr, name, ratio)

```


```{r ONETIME_OSRupdated, eval=FALSE}
# take osr history through 2018
# estimate 2019 and 2020 using:
#   fy growth rates for taxes from qtax data
#   fy growth rates for nontax from Moody's july 2020 state gdp

osrhist <- readRDS(here::here("data", "osr_census_history.rds"))
summary(osrhist)

growth <- bind_rows(taxgrowth, nontaxgrowth)

osrupdate <- bind_rows(osrhist, 
                       growth %>% filter(year %in% 2020)) %>%
  group_by(stabbr, name) %>%
  arrange(year) %>%
  mutate(value=ifelse(year %in% 2020, 
                      value[year==2019] * ratio,
                      value)) %>%
  ungroup %>%
  select(year, stabbr, name, value) %>%
  pivot_wider() %>%
  mutate(tottax=ifelse(is.na(tottax), naz(iit) + naz(gst) + naz(cit) + naz(othertax), tottax),
         osr=ifelse(is.na(osr), tottax + nontax, osr)) %>%
  pivot_longer(cols=-c(stabbr, year))


st <- "NJ"
osrhist %>% filter(stabbr==st, year >= 2018) %>% arrange(year)
growth %>% filter(stabbr==st) %>% arrange(name, year)
osrupdate %>% filter(stabbr==st, year>=2018) %>% arrange(year)

osrupdate %>%
  filter(year >= 2018) %>%
  arrange(year, name)

saveRDS(osrupdate, here::here("data", "osr_census_updated.rds"))

rm(osrhist, taxgrowth, nontaxgrowth, osrupdate)

osrupdate <- readRDS(here::here("data", "osr_census_updated.rds"))
osrupdate %>%
  filter(stabbr=="PA", name=="osr") %>%
  filter(year >= 1990) %>%
  ggplot(aes(year, value)) +
    geom_line() +
    geom_point() +
    scale_x_continuous(breaks=seq(1900, 2030, 5))

```



## OSR as % of GDP
```{r ONETIME_osr_gdppct, include=FALSE}
# Compute long-run target revenue as % of gsp
stgdp <- readRDS(here::here("data", "stgdp.rds"))
osr <- readRDS(here::here("data", "osr_census_updated.rds"))  # ends 2020

gdp_base <- stgdp %>%
  filter(year >= 1990, year <= 2019) %>%
  select(stabbr, year, gdp=moodys_dec2020)

osr_base <- osr %>%
  filter(year >= 1990, year <= 2019) %>%
  mutate(value=naz(value)) %>%
  select(stabbr, year, name, rev=value)

pctgdp <- left_join(osr_base, gdp_base, by = c("stabbr", "year")) %>%
  mutate(pctgdp=rev / gdp * 100) %>%
  arrange(stabbr, name, year) %>%
  group_by(stabbr, name) %>%
  mutate(p1=ma(pctgdp, 1),
         p2=ma(pctgdp, 2),
         p3=ma(pctgdp, 3),
         p4=ma(pctgdp, 4),
         p5=ma(pctgdp, 5),
         p10=ma(pctgdp, 10)) %>%
  filter(year==2019) %>%
  select(year, stabbr, name, p1:p10) %>%
  ungroup

pctgdp %>% filter(stabbr=="NJ")
pctgdp %>% filter(stabbr=="MA")
  
saveRDS(pctgdp, here::here("data", "osr_pctgdp.rds"))

```


##  Pew projections of own-source revenue
```{r}
fn <- "Boyd Extraction Of Pew OSR Projections.xlsx"
sts <- c("MN", "NJ")

get_stosr <- function(st){
  read_excel(here::here("ignore", "pew", fn),
             sheet=st,
             range = "A3:J38",
             col_names = c(LETTERS[1:10])) %>%
    mutate(stabbr=st) %>%
    select(year=A, 
           stabbr,
           pew_precovid=B,
           pew_baseline=F,
           pew_downside=J)
}

get_stosr("MN")

pewosr <- map_dfr(sts, get_stosr) %>%
  pivot_longer(-c(year, stabbr),
               names_to = "scenario",
               values_to = "osr")

saveRDS(pewosr, here::here("data", "pew_osrforecasts.rds"))


```



# Other data

## S&P 500 total returns
```{r ONETIME_sp500tr}
sp500tr <- getSymbols('^SP500TR', 
                      src='yahoo', 
                      from = "1990-01-01",
                      periodicity = "daily",
                      auto.assign=FALSE) %>%
  as_tibble(rownames="date") %>%
  setNames(str_to_lower(names(.)))

sp500tr2 <- sp500tr %>%
  mutate(year=year(date)) %>%
  group_by(year) %>%
  filter(date==max(date)) %>%
  ungroup %>%
  mutate(pch=sp500tr.adjusted / sp500tr.adjusted[match(year - 1, year)] * 100 - 100)

sp500tr3 <- sp500tr2 %>%
  select(year, sp500tr=sp500tr.adjusted, pch)

saveRDS(sp500tr3, here::here("data", "sp500tr.rds"))

```


```{r ONETIME_equities}
sp500 <- readRDS(here::here("data", "sp500tr.rds")) %>% # CY
  filter(year <= 2020)

usequity <- read_excel(here::here("ignore", "boyd", "finance.xlsx"), sheet="usequity")
# compute usequity growth vs 2019

usequity2 <- usequity %>%
  filter(year >= 2021) %>%
  mutate(across(.cols=-year, ~ cumprod(1 + .)))

equity_fc <- sp500 %>%
  select(-pch) %>%
  full_join(usequity2) %>%
  mutate(across(c(pew_covidbase, pew_fedalt), ~ ifelse(year <= 2020, sp500tr, sp500tr[year==2020] * .)))

equity_fc %>%
  select(-sp500tr) %>%
  pivot_longer(-year) %>%
  ggplot(aes(year, value, colour=name)) +
  geom_line() +
  geom_point()

```



## Capital gains

We have capgains under:

*   CBO pre-covid (Jan 2020)
*   CBO July-ish (sep 2020)
*   fedalt (we will construct)


```{r ONETIME_uscapgains, eval=FALSE}
usgdp <- readRDS(here::here("data", "usgdp.rds"))
capgains1 <- read_excel(here::here("ignore", "boyd", "finance.xlsx"), sheet="capgains")

capgains <- capgains1 %>%
  select(year, cbo_precovid=cbojan2020, cbo_jul2020=cbospliced)
ht(capgains)

# forecast capgains variants using usgdp and sp500
# estimate through 2019
cgest <- usgdp %>%
  filter(year >= 1995, year <= 2019) %>%
  select(year, gdp=moodys_dec2020) %>%
  mutate(gdp=gdp / 1e3) %>%
  left_join(capgains %>% select(year, cg=cbo_jul2020), by = "year") %>%
  left_join(equity_fc %>% select(year, sp500tr), by = "year")

# fit a capital gains model
mod <- cgest %>%
  as_tsibble(index=year) %>%
  filter(year <= 2019) %>%
  model(ARIMA(cg ~ gdp + sp500tr))
# report(mod)
# glance(mod)
# mod %>%
#   gg_tsresiduals()

saveRDS(mod, here::here("data", "cgmodel.rds"))

# show the fit
mod %>% 
  augment() %>%
  select(year, cg, fit=.fitted) %>%
  pivot_longer(-year) %>%
  ggplot(aes(year, value, colour=name)) +
  geom_line() +
  geom_point() +
  ggtitle("Model fit for capital gains") +
  theme_bw()

# prepare fcbase, with data needed to forecast cap gains for each econ-sp500 combination
gdpl <- usgdp %>%
  filter(year >= 1995) %>%
  select(-gdphist) %>%
  mutate(across(-year, ~ . / 1e3)) %>%
  pivot_longer(-year, values_to="gdp")

eql <- equity_fc %>%
  select(-sp500tr) %>%
  pivot_longer(cols=-year, values_to="sp500tr")

fcbase <- gdpl %>%
  filter(year %in% 1995:2030) %>%
  rename(gdpname=name) %>%
  full_join(eql %>%
              filter(year %in% 1995:2030) %>%
              rename(eqname=name),
            by = "year")
fcbase

# forecast capital gains
f <- function(df){
  # forecast for a single group
  df %>%
    as_tsibble(index=year) %>%
    forecast(mod, new_data=.) 
}

cgfcast <- fcbase %>%
  group_by(gdpname, eqname) %>%
  group_modify(~ f(.x)) %>%
  ungroup %>%
  rename(cgfcast=.mean)

count(cgfcast, gdpname, eqname)

cgfcast %>%
  filter(year >= 2015) %>%
  filter((gdpname=="cbo_precovid" & eqname=="pew_covidbase") |
         (gdpname=="cbo_jul2020" & eqname=="pew_covidbase") |
         (gdpname=="moodys_dec2020" & eqname=="pew_covidbase") |
         (gdpname=="fedalt" & eqname=="pew_covidbase") |
         (gdpname=="fedalt" & eqname=="pew_fedalt")) %>%
  mutate(grp=paste0(gdpname, "-", eqname)) %>%
  ggplot(aes(year, cgfcast, colour=grp)) +
  geom_line() +
  geom_point()
           
saveRDS(cgfcast, here::here("data", "cgfcast.rds"))


```



```{r ONETIME_state_capgains, eval=FALSE}
ht2 <- readRDS(here::here("data", "ht2.rds"))
ht2
capgains_state <- ht2 %>%
  filter(agi_stub==0) %>%
  select(year, stabbr, value=a01000) %>%
  mutate(name="capgains",
         src="SOI_HT2",
         fullname=paste0(name, "_", src))

# capgains_state %>%
#   filter(agi_stub==0, stabbr %in% c("NJ", "NY", "US", "CT")) %>%
#   ggplot(aes(year, cgpchya, colour=stabbr)) +
#   geom_line() +
#   geom_point()
saveRDS(capgains_state, here::here("data", "statecapgains.rds"))
rm(ht2, capgains_state)

```




# Greg and Kimberly notes

## 2020-12-21
We are looking forward to working with you as time allows on the project to sharpen our five-year revenue forecasts in a (now actual) downturn and recovery, with the initial focus on New Jersey.  


In an effort to see if we can jump start the conversation, I’ve included a few high-level notes on what we’ve already discussed as well as some thoughts on how to make this as straightforward as possible.   Will follow up with something more detailed, including responses to points you raised at the end of October on New Jersey, and to complete the hand-off to Kimberly who is poised to give this more day in day out attention.


First off, I think the general language in the contract on the revenue(*see bottom of email) works to our advantage, in terms of defining the goal in general terms supported by billable hours.  But if we need to more formally or informally document the scope of work, please let us know.   Also, note that we’ve highlighted the revenue piece in the contract for emphasis.  While we still would enjoy circling back with you on our overall scenario methodology, this is less of a priority and I think will be a straightforward exercise when the time is right.

In terms of specific revenue lines, I think we are in agreement on major state sources, defined as Personal Income, Sales, and Corporate Tax revenue, as well as state fee revenue.  As discussed, capital gains within personal income is also important and the definition of fee revenue is likely to vary by state.  Note that we’ll send along something pre-existing that seems to fit this definition well in New Jersey.

We also thought that it might help to clarity that although we would eventually like to document a methodology for doing this in a downturn/recovery, we don’t have any intention to publish results, at least not without your OK.  Noting this as I thought it might help to alleviate concern around generating a forecast that will differ from what the state is using.  Will make note in NJ follow-up around our thoughts on which in-state forecast might be more useful as a starting point.
 
Another thought on keeping this efficient has to do with having you all review our current OSR methodology.  Initially, we were thinking of discussing this as a second step down the road.  Specifically because the more in-depth approach was designed specifically because we know that the long-run GSP to OSR relationship does not work over shorter periods of downturn and recovery.  That said, if there is value to reviewing methodology here, sooner rather than later, that would be cool with us.  I’d just re-emphasize that we are more looking for the work you all might do to help us make our methodology sharper, as opposed to the other way around or having any need to reconcile. 
 
We’ll also follow up with the easiest to follow spreadsheet for the assumptions we are using, including capital market assumptions, in our downside scenario.   Two thoughts on this in the category of keeping things simple.  The first is that we don’t think it’s necessary for you all to do in depth stochastic or other analysis, really just preferring to focus on the revenue.  Related to this, we can share 1-2 documents that summarize results under the new scenarios for New Jersey based on work the Terry Group has done.
 
Assuming New Jersey is the right place to start, we would still be eager to discuss other states towards the goal of developing a more general approach.  We can follow-up with more details when the time is right, with the usual note that we are more than happy to prioritize based in part of what you all think is most interesting and useful.

Please let us know if you have questions.  Email 2 of 2 on this topic with some of the additional thoughts and details to follow.
 

Thanks,

Greg (and Kimberly) 

*3.7. Provide consulting support in relation to economic scenarios, revenue scenarios, and stress testing to inform Pew's stress testing methodology and related materials (collectively, Pew Materials). The consulting will be focused on exploring methods to develop and apply a general framework for forecasting state-specific revenue under alternative economic scenarios, particularly recession scenarios, taking into consideration the cyclical effects of these scenarios. 

